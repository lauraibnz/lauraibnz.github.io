<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>laura.ibnz</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Sans:ital,wght@0,100..700;1,100..700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="./assets/css/style.css" />
  </head>
  <body>
    <div class="page">
      <header class="sidebar">
        <h1><a href="./">laura.ibnz</a></h1>
        <img src="./assets/img/avatar.png" alt="Laura Ibáñez" />
        <nav aria-label="Primary">
          <a href="https://scholar.google.es/citations?user=EczEU_cAAAAJ&hl=ca" target="_blank" rel="noreferrer">View Google Scholar</a>
          <a href="https://github.com/lauraibnz" target="_blank" rel="noreferrer">View GitHub</a>
          <a href="https://huggingface.co/lauraibnz" target="_blank" rel="noreferrer">View Hugging Face</a>
          <a href="mailto:laura.ibanez@upf.edu">Contact</a>
        </nav>
      </header>

      <main class="content">
        <p>
          Laura Ibáñez-Martínez is a PhD student and researcher at the Music Technology Group (MTG), Universitat Pompeu Fabra
          (UPF). Her work focuses on controllable music generation from disentangled representations,
          and she carries out her research under the supervision of Xavier Serra and Martín Rocamora.
        </p>

        <section>
          <h2>Research Interests</h2>
          <ul>
            <li>
              <strong>Controllability:</strong> learning disentangled representations for controllable music generation, 
              particularly through structure–timbre disentanglement in music audio.
            </li>
            <li>
              <strong>Interpretability:</strong> evaluating what musical information is encoded in generative model 
              representations beyond standard downstream tasks.
            </li>
            <li>
              <strong>Adaptability:</strong> building generative music systems that can be adapted to personal data 
              under realistic practical constraints.
            </li>
            <li>
              <strong>Usability:</strong> supporting integration of generative music systems into real-world 
              music workflows through intuitive interfaces.
            </li>
          </ul>
        </section>

        <section>
          <h2>Publications</h2>
          <ul class="publications">
            <li class="publication">
              Laura Ibáñez-Martínez, Chukwuemeka Nkama, Andrea Poltronieri, 
              Xavier Serra, Martín Rocamora. 
              “Evaluating Disentangled Representations for Controllable Music Generation.” 
              <em>IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, 2026.
              <a href="https://arxiv.org/abs/2602.10058"
                 target="_blank"
                 rel="noreferrer">[Paper]</a>
              <a href="https://github.com/lauraibnz/synesis"
                 target="_blank"
                 rel="noreferrer">[Repository]</a>
            </li>
            <li class="publication">
              Roser Batlle-Roca, Laura Ibáñez-Martínez, Xavier Serra, 
              Emilia Gómez, Martín Rocamora. 
              “MusGO: A Community-Driven Framework for Assessing Openness in Music-Generative AI.” 
              <em>International Society for Music Information Retrieval Conference (ISMIR)</em>, 2025.
              <a href="https://arxiv.org/abs/2507.03599"
                 target="_blank"
                 rel="noreferrer">[Paper]</a>
              <a href="https://github.com/roserbatlleroca/MusGO_framework"
                 target="_blank"
                 rel="noreferrer">[Repository]</a>
              <a href="https://roserbatlleroca.github.io/MusGO_framework/"
                 target="_blank"
                 rel="noreferrer">[Website]</a>
            </li>
          </ul>
        </section>

        <section>
          <h2>Festivals & Hackathons</h2>
          <ul>
            <li>
              Sónar+D Project Area — Presentation of “MIDI-AudioLDM” 
              at the interactive exhibition space of Sónar by Day (2023).
              <a href="https://huggingface.co/spaces/lauraibnz/midi-audioldm"
                 target="_blank"
                 rel="noreferrer">[Demo]</a>
            </li>
        
            <li>
              Ars Electronica AIxMusic Online Hackathon — Participant in the 
              "Generate. Interpolate. Orchestrate." project
              presented at Ars Electronica (2020).
              <a href="https://soundscape-ai.netlify.app/"
                 target="_blank"
                 rel="noreferrer">[Demo]</a>
            </li>
          </ul>
        </section>

        <section>
          <h2>Professional Experience</h2>
          <ul>
            <li>
              Music Technology Group (MTG), UPF —
              PhD Researcher (Barcelona, Spain, 2024–<em>present</em>)
            </li>
        
            <li>
              PIXELYNX —
              Machine Learning Engineer (California, US – hybrid from Berlin, Germany, 2023–2024)
            </li>
        
            <li>
              AudioShake —
              Machine Learning Engineer, freelance (California, US – remote, 2023)
            </li>
        
            <li>
              Pixtunes GmbH —
              Machine Learning Engineer (Berlin, Germany, 2019–2021)
            </li>
          </ul>
        </section>

        <section>
          <h2>Education</h2>
          <ul>
            <li>
              Universitat Pompeu Fabra (UPF) —
              PhD in Information and Communication Technologies (2024–<em>present</em>)
            </li>
        
            <li>
              Universidad Nacional de Educación a Distancia (UNED) —
              M.Sc. in Artificial Intelligence Research (2021–2023)
              <ul>
                <li>
                  Laura Ibáñez-Martínez.
                  “MIDI-AudioLDM: MIDI-Conditional Text-to-Audio Synthesis Using ControlNet on AudioLDM.”
                  Master’s thesis, 2023.
                  <a href="https://e-spacio.uned.es/entities/publication/e432f214-0d23-4060-9d6a-ebbb23b03bf5"
                     target="_blank"
                     rel="noreferrer">[Thesis]</a>
                </li>
              </ul>
            </li>
        
            <li>
              Universitat Politècnica de Catalunya (UPC) —
              B.Sc. in Industrial Electronics and Automatic Control Engineering (2013–2019)
              <ul>
                <li>
                  Erasmus+ Programme, Technische Universität Berlin (2018–2019)
                </li>
              </ul>
            </li>
        
            <li>
              Escola Superior de Música de Catalunya (ESMUC) —
              Bachelor of Music in Performance – Classical and Contemporary Guitar (2013–2017)
            </li>
          </ul>
        </section>

        <section>
          <h2>Talks</h2>
          <ul>
            <li>
              Explorando IA con prácticas artísticas —
              Sala de Arte Joven, as part of the exhibition “Materia Afectiva” (2025)
            </li>
            <li>
              IA y Música: MIDI-AudioLDM —
              Volumens Festival (2023)
            </li>
          </ul>
        </section>

        <section>
          <h2>Other AI-related Projects</h2>
          <ul class="projects">
            <li>
              Materia Afectiva: Hotlines — AI conversational agent developed for the exhibition (2025).
              <a href="https://www.neo2.com/materia-afectiva-una-mirada-a-la-inteligencia-artificial/"
                 target="_blank" rel="noreferrer">[Press]</a>
            </li>
        
            <li>
              Cellar Song for Five Voices — AI-generated text, voice and image (2021).
              <a href="https://www.virtuallyrealityevents.com/emmettwilliams"
                 target="_blank" rel="noreferrer">[Project]</a>
            </li>
        
            <li>
              THISPERSONDOESNOTEXIST — AI-generated image (2021).
              <a href="https://www.michaelbrailey.com/thispersondoesnotexist"
                 target="_blank" rel="noreferrer">[Project]</a>
            </li>
        
            <li>
              bod [包家巷] for PW-Magazine — AI-generated image (2020).
              <a href="https://pw-magazine.com/2020/bod-sentient-sounds-impossible-to-avoid"
                 target="_blank" rel="noreferrer">[Project]</a>
            </li>
          </ul>
        </section>
      </main>
    </div>
  </body>
</html>
